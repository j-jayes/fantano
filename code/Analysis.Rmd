---
title: "Analysis"
author: "JJayes"
date: "01/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidymodels)
library(lubridate)
library(glue)

theme_set(theme_light())
```

## Purpose

EDA and modelling for Needle Drop Dataset to predict score from words

### Reading in data

```{r}
df <- read_rds("data/clean_data_1_july.rds")

colnames(df)

# we have some missing score data so we will filter it out.
df <- df %>% 
  filter(!is.na(score))
```

## EDA

What does the data look like?

```{r}
df %>% skimr::skim()
```

### How does Fantano score albums?

```{r}
df %>% 
  count(score) %>% 
  ggplot(aes(score, n)) +
  geom_col(fill = "lightblue") + # Come back to colours
  labs(x = "Album score by Fantano",
       y = "Number of albums")
```

A lovely distribution centred around 7/10.

### Scores over time?

```{r}
library(plotly)

g <- df %>% 
  mutate(title = str_remove(video_title, "ALBUM REVIEW")) %>% 
    ggplot(aes(published_date, score, text = glue("{title} - {score}"))) +
    geom_jitter(aes(colour = score),
                width = 0, height = .6, show.legend = FALSE) +
    geom_smooth(method = "lm") +
    labs(y = "Album score",
         x = "Review date")

ggplotly(g, tooltip = "text")

```

With ggiraph

```{r}

g <- df %>% 
  mutate(title = str_remove(video_title, "ALBUM REVIEW")) %>% 
    ggplot(aes(published_date, score, text = glue("{title} - {score}"))) +
    geom_jitter(aes(colour = score),
                width = 0, height = .6, show.legend = FALSE) +
    geom_smooth(method = "lm") +
    labs(y = "Album score",
         x = "Review date")

ggplotly(g, tooltip = "text")

```


### Scores and video statistics?

```{r}
df %>% 
  select(score, contains("statistics")) %>% 
  pivot_longer(-score, names_to = "stat") %>% 
  mutate(stat = str_replace_all(stat, "_", " "),
         stat = str_to_title(stat)) %>% 
  ggplot(aes(value, score)) +
  geom_jitter(alpha = .5,
              height = .8,
              colour = "lightblue") +
  geom_smooth() +
  scale_x_log10(labels = scales::number_format(accuracy = 1)) +
  facet_wrap(~ stat, scales = "free_x") +
  labs(x = NULL,
       y = NULL,
       title = "How do viewers of Needle Drop videos respond to different scores?")

```

What can we say about this?

As people comment more and dislike the video, the scores get lower, potentially indicative of anger at Fantano scoring the albums lower than his viewers would have liked.

We can also make a linear model and display the results as a tie-fighter plot. This shows that when we log the statistic, comment count and dislike count are negatively associated with the score.

```{r}
df %>% 
  select(score, contains("statistics")) %>% 
  pivot_longer(-score, names_to = "stat") %>% 
  mutate(stat = str_replace_all(stat, "_", " "),
         stat = str_to_title(stat),
         value = log(value)) %>% 
  nest(data = -stat) %>% 
  mutate(
    fit = map(data, ~ lm(score ~ value, data = .x)),
    tidied = map(fit, ~ tidy(.x, conf.int = T))
  ) %>% 
  unnest(tidied) %>% 
  filter(term != "(Intercept)") %>% 
  ggplot(aes(estimate, stat)) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) +
  geom_point(colour = "lightblue", cex = 5) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Effect of log of term on album score",
       y = NULL,
       title = "What is the correlation between view statistics and album score?")

```

What is the relationship between duration of video and the score? Does Fantano spend more time time describing an album that he really enjoyed?

```{r}
# df %>% 
#   ggplot(aes(duration, score)) +
#   geom_smooth() +
#   geom_jitter(colour = "lightblue") +
#   scale_x_log10(lim = c(150, 3000)) +
#   labs(x = "Duration of video in seconds",
#        y = "Album score") +
#   scale_y_continuous(labels = scales::number_format(accuracy = 1)) 

df %>% 
  lm(score ~ log(duration), data = .) %>% tidy() 
  # kableExtra::kable() maybe do this for post
```

How else can we ask this question?

```{r}
library(ggridges)

df %>% 
  # filter(score > 2) %>% maybe include this limit?
  ggplot(aes(x = duration, y = factor(score), fill = score)) +
  geom_density_ridges(show.legend = F) +
  scale_fill_gradient2(low = "blue", high = "orange", midpoint = 5) +
  scale_x_log10(lim = c(200, 2000)) +
  labs(y = "Album score",
       x = "Duration of video in seconds",
       title = "How does review duration relate to score?")
```

### Text

What does he say in his reviews?

```{r}
library(tidytext)

words <- df %>% 
  unnest_tokens(word, text) %>% 
  select(score, video_title, word)

words <- words %>% 
  anti_join(stop_words)

words %>% 
  count(word, sort = T) %>% 
  head(100) %>% view()

words %>% 
  count(word, sort = T) %>% 
  slice_max(n, n = 50, with_ties = F) %>% 
  mutate(tags = fct_reorder(tags, n)) %>% 
  ggplot(aes(n, tags, fill = n)) +
  geom_col()

```


### Tags

```{r}
tags <- df
  
tags <- tags %>% select(tags) %>% 
  unnest_tokens(output = tags, input = tags, token = stringr::str_split, pattern = ", ") %>% 
  anti_join(stop_words, by = c("tags" = "word"))

tags %>% 
  count(tags, sort = T) %>% 
  slice_max(n, n = 50, with_ties = F) %>% 
  mutate(tags = fct_reorder(tags, n)) %>% 
  ggplot(aes(n, tags, fill = n)) +
  geom_col()

tags %>% 
  filter(str_detect(tags, "rvwz")) %>% 
  count(tags, sort = T)

df %>% 
  filter(str_detect(tags, "rvwz"))

# so we can remove the rvwz from the tags
```

### Audio features?

```{r}
df <- read_rds("data/audio_features_small.rds")

test_7 <- df %>% nest(data = c(track_name, track_id, track_explicit, danceability, energy, 
    key, loudness, mode, speechiness, acousticness, instrumentalness, 
    liveness, valence, tempo, duration_ms, time_signature, spotify_track_features)) %>% 
  distinct(video_id, .keep_all = T)



df %>% 
  ggplot(aes(danceability)) +
  geom_density()

df %>% 
  ggplot(aes(danceability, instrumentalness, colour = factor(score))) +
  geom_point()

df %>% 
  count(time_signature, sort = T)

df %>% count(track_explicit, sort = T)

df %>% count(key, time_signature, sort = T)
```


```{r}
df %>% 
  ggplot(aes(spotify_artist_popularity, score)) +
  geom_jitter() +
  geom_smooth(method = "lm")

```

Hahah he's such a hipster. more popular leading to lower scores.

```{r}
df %>% 
  ggplot(aes(x = spotify_artist_popularity, y = factor(score), fill = score)) +
  geom_density_ridges(show.legend = F) +
  scale_fill_gradient2(low = "blue", high = "orange", midpoint = 5) +
  labs(y = "Album score",
       x = "spotify_artist_popularity",
       title = "How does spotify_artist_popularity relate to score?")

```

Are the fans normies?? 

How can we tell? We need to correct for popularity of artist when analysing how much they agree or disagree with Fantano. Maybe divide comments and dislikes by views?

Becasuse it makes sense that comment count increases with populairty - you'll watch the reviews that are of artists you care about.

```{r}
df %>% 
  ggplot(aes(video_statistics_comment_count, spotify_artist_popularity)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_log10()

```

That's hilarious!

If we correct for views it's not as strong.

```{r}
df %>% 
  mutate(comments_over_views = video_statistics_comment_count / video_statistics_view_count) %>% 
  ggplot(aes(comments_over_views, spotify_artist_popularity)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_log10()
```

What about the ratio of likes to dislikes? Or comments to dislikes?

```{r}
df %>% 
  mutate(likes_to_dislikes = video_statistics_like_count / video_statistics_dislike_count) %>% 
  ggplot(aes(likes_to_dislikes)) +
  geom_density() +
  facet_wrap( ~ score, scales = "free_y")

```



Another way to put this is to look at the popularity of the artist and the dislike count. wait what about ratio or views to dislikes??

```{r}
df %>% 
  ggplot(aes(video_statistics_dislike_count, spotify_artist_followers)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_log10() +
  scale_y_log10()

```


```{r}
df %>% 
  mutate(dislikes_over_views = video_statistics_dislike_count / video_statistics_view_count) %>% 
  ggplot(aes(dislikes_over_views, spotify_artist_followers)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_log10() +
  scale_y_log10()
```

We could do a regression with dislikes as dep var and popularity and views as xs?

```{r}
df %>% 
  lm(log(video_statistics_dislike_count) ~ log(spotify_artist_followers) + 
       log(video_statistics_view_count), 
     data = .) %>% tidy()
```

```{r}
df %>% 
  ggplot(aes(x = danceability, y = factor(score), fill = score)) +
  geom_density_ridges(show.legend = F) +
  scale_fill_gradient2(low = "blue", high = "orange", midpoint = 5) +
  labs(y = "Album score",
       x = "danceability",
       title = "How does danceability relate to score?")

df %>% 
  group_by(video_id) %>% 
  mutate(danceability_mean = mean(danceability)) %>% 
  ungroup() %>% 
  ggplot(aes(x = danceability_mean, y = factor(score), fill = score)) +
  geom_density_ridges(show.legend = F) +
  scale_fill_gradient2(low = "blue", high = "orange", midpoint = 5) +
  labs(y = "Album score",
       x = "danceability",
       title = "How does danceability relate to score?")

df %>% 
  group_by(video_id) %>% 
  mutate(danceability_var = var(danceability)) %>% 
  ungroup() %>% 
  ggplot(aes(x = danceability_var, y = factor(score), fill = score)) +
  geom_density_ridges(show.legend = F) +
  scale_fill_gradient2(low = "blue", high = "orange", midpoint = 5) +
  labs(y = "Album score",
       x = "danceability",
       title = "How does danceability relate to score?")
```

Popularity?

```{r}
df %>% 
  mutate(spotify_artist_popularity = 
           spotify_artist_popularity - spotify_artist_popularity %% 10) %>% 
  ggplot(aes(x = danceability, y = factor(spotify_artist_popularity), fill = spotify_artist_popularity)) +
  geom_density_ridges(show.legend = F) +
  scale_fill_gradient2(low = "blue", high = "orange", midpoint = 50) +
  labs(y = "spotify_artist_popularity",
       x = "danceability",
       title = "How does danceability relate to spotify_artist_popularity?")

```


```{r}
df_features <- df %>% 
  select(score, spotify_artist_popularity, danceability:time_signature) %>% 
  rename_all(.funs = ~ str_replace_all(.x, "_", " ")) %>%
  rename_all(.funs = str_to_title) %>% 
  pivot_longer(-c(Score, `Spotify Artist Popularity`), 
               names_to = "audio_feature_name", 
               values_to = "audio_feature_value") %>% 
  pivot_longer(-c(audio_feature_name, audio_feature_value), 
               names_to = "music_metric", 
               values_to = "score_value")



draw_features_ridges <- function(tbl, feature, metric){
  
  tbl <- tbl %>% 
    filter(audio_feature_name == feature,
           music_metric == metric) %>% 
    mutate(score_value = if_else(music_metric == "Spotify Artist Popularity", 
                                  score_value - score_value %% 10, 
                                  score_value))
  
  mid_point = mean(tbl$score_value)
  
  mean_feature_value = round(mean(tbl$audio_feature_value, na.rm = T), 2)
  
  tbl %>% 
    ggplot(aes(audio_feature_value, factor(score_value), fill = score_value)) +
    geom_density_ridges(show.legend = F) +
    scale_fill_gradient2(low = "blue", high = "orange", midpoint = mid_point) +
    geom_vline(xintercept = mean_feature_value, lty = 2) + 
    labs(y = glue("{metric}"),
         x = glue("{feature}"),
         title = glue("How does {feature} relate to {metric}?"),
         subtitle = glue("Mean {feature} is {mean_feature_value}"))
  
}

draw_features_ridges(df_features, "Energy", "Spotify Artist Popularity")

draw_features_ridges(df_features, "Energy", "Score")

```

Crosstalk for a plot that allows selection without shiny

```{r}
library(crosstalk)

shared_features <- df_features


bscols(widths = c(3,NA),
  list(
    filter_select("audio_feature_name", "audio_feature_name", shared_features,
                  ~ifelse(audio_feature_name == 0, "Danceability", "Energy", "Loudness")),
  ),
  d3scatter(shared_features, ~audio_feature_value, ~score_value, ~factor(score_value), width="100%", height=250),
)


```


### Recipe for modelling

Prep for modelling

```{r}
small_sample <- df %>% na.omit()

# %>% sample_n(500)

skimr::skim(small_sample)

set.seed(123)
spl <- initial_split(small_sample)

train <- training(spl)
test <- testing(spl)

folds <- vfold_cv(train, 5)

```


```{r}
library(textrecipes)

basic_rec <- recipe(score ~ ., data = train) %>% 
    # update role for ids
    update_role(video_id, 
                video_title, 
                video_description, 
                score_raw, 
                new_role =  "id") %>% 
    # make score numeric ~ not sure why this has to be done again... recipes quirk
    step_mutate(score = as.numeric(score)) %>% 
    # making duration into seconds rather than 
    step_mutate(duration = as.numeric(duration)) %>% 
    # the numeric vars really need to be logged
    step_log(contains("statistic"), duration, base = 10) %>% 
    # make the tags and text tokens at the word level.
    step_tokenize(text) %>% 
    # remove stopwords
    step_stopwords(text) %>% 
    step_tokenize(tags, token = "regex", options = list(";")) %>% 
    # we'll tune these later
    step_tokenfilter(tags, max_tokens = 20) %>% 
    # we'll tune these later
    step_tokenfilter(text, max_tokens = tune()) %>% 
    step_tf(text, tags) %>% 
    # make date
    step_date(published_date, 
              # make lots of features just to see
              features = c("week", "dow", "month", "year"),
              keep_original_cols = F)

```


### Start with a logistic regression model

```{r}
library(usemodels)
usemodels::use_glmnet(formula = score ~ ., data = train)

glmnet_recipe <- 
  basic_rec %>% 
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors())

# glmnet_recipe %>% prep() %>% juice()

glmnet_spec <- 
  linear_reg(penalty = tune(),
             mixture = 1) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet") 

glmnet_workflow <- 
  workflow() %>% 
  add_recipe(glmnet_recipe) %>% 
  add_model(glmnet_spec) 

glmnet_grid <- tidyr::crossing(penalty = 10^seq(-6, -1, length.out = 10),
                               max_tokens = c(200, 500)) 

glmnet_tune <- 
  tune_grid(glmnet_workflow, resamples = folds, grid = glmnet_grid)

glmnet_tune %>% 
  autoplot()

glmnet_tune %>% 
  collect_metrics()

glmnet_tune %>% 
  select_best(metric = "rsq")

glmnet_workflow_final <- glmnet_workflow %>%
  finalize_workflow(parameters = select_best(glmnet_tune, metric = "rsq"))
```

Hard code final values for the moment

```{r}
# glmnet_workflow_final <- glmnet_workflow %>% 
#   finalize_workflow(parameters = tibble(penalty = 0.0278, mixture = 1))

glm_fit <- glmnet_workflow_final %>% 
  fit(test)

fit <- glm_fit %>% pull_workflow_fit()

fit$fit$beta %>% 
  tidy() %>% 
  mutate(col = parse_number(column),
         abs_value = abs(value)) %>% 
  filter(col == max(col)) %>%
  slice_max(abs_value, n = 20, with_ties = F) %>% 
  mutate(row = fct_reorder(row, value)) %>% 
  ggplot(aes(value, row)) +
  geom_col() +
  geom_vline(xintercept = 0, lty = 2)

```

### Now let's use a 


### Next let's go with a bagged tree model

```{r}
library(baguette)

bag_recipe <- 
  basic_rec %>% 
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_mutate(score = as.numeric(score))


bag_spec <- bag_tree() %>% 
  set_engine("rpart") %>% # 25 ensemble members 
  set_mode("regression")


bag_wf <- workflow() %>% 
    add_recipe(bag_recipe) %>% 
    add_model(bag_spec)

set.seed(123)
bag_cars <- bag_wf %>% 
    fit_resamples(resamples = folds)

bag_cars
```

